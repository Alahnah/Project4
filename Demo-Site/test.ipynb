{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "# bypasses bot detection\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\")\n",
    "# prevents the browser from actually opening\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "# create webdriver instance\n",
    "driver = webdriver.Chrome(chrome_options)\n",
    "# go to the url\n",
    "url = 'https://www.indeed.com/viewjob?jk=6739c6151a7e7b7f&tk=1hdhioeihh4et800&from=hp&advn=5517679427952387&adid=408874990&ad=-6NYlbfkN0CgXERUs4j-EIIOqSh8J3cPc4-w9nP6AWKLVdR11raBE3nTHRXmTzAHry7ntBtdo9fFq5hT_9kYPrEXdSiv_vC9gKJHY0TaB30J7g4xvjByJfY0Wh1L_5moU3y8hhLsjzv9QdQ7wVaa1VGux-a4OEhKEYlKrq2J88Vo5IwL45uRYkMXlmIyV5MshxtykHErUryJiTJB721-pfn71ShBRB01LZjKh85JfSfjru58qaVzwGKiyGwR3xH4fW-MC7vtDbJfV0A3002z9-G0klpI2ScTtC7kpIQzNBdgfSleQrKZ6DHixOe0NRwgJJ5r1dk_GgAU5q6Mv5Nv0ycfDOREZw4Z-s0Ch0kMH5DjKCbtA7Dnu257PXwso9Ni5mY3XhLbrNiqpL6_Bvh7DRe4DsJe4zhV7vHa9lYaGpk0GnTHSJiU6ge0ovil-slzBdQzbhq59E3pNjZf5yT5LrYdmW7laS92EEU83UMu7BHYPoEDwlCg6_sdAKHtS4U-FFEdKJfQw3O_8L3NY5LqDCulahah7svbQUgllWQnY4w%3D&pub=4a1b367933fd867b19b072952f68dceb&xkcb=SoCX-_M3JxtuPXTAHJ0LbzkdCdPP&xpse=SoAS6_I3JxttjPAUob0JbzkdCdPP&vjs=3'\n",
    "driver.get(url)\n",
    "html_content = driver.page_source\n",
    "# close the webdriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for things to collect\n",
    "title = None\n",
    "location = None\n",
    "departments = None\n",
    "salary = None\n",
    "company = None\n",
    "description = None\n",
    "requirements = None\n",
    "benefits = None\n",
    "telecommuting = None\n",
    "has_company_logo = None\n",
    "has_questions = None\n",
    "employment_type = None\n",
    "required_experience = None\n",
    "required_education = None\n",
    "industry = None\n",
    "function = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title\n",
    "title_element = soup.find('h1', class_='jobsearch-JobInfoHeader-title')\n",
    "if title_element:\n",
    "    title = title_element.text\n",
    "    # print(title)\n",
    "\n",
    "# location\n",
    "location_element = soup.find('div', {'data-testid': 'inlineHeader-companyLocation'})\n",
    "if location_element:\n",
    "    location = location_element.text\n",
    "    # print(location)\n",
    "\n",
    "# departments\n",
    "# salary\n",
    "\n",
    "# company\n",
    "company_element = soup.find('div', {'data-testid': 'inlineHeader-companyName'})\n",
    "if company_element:\n",
    "    company = company_element.text\n",
    "    # print(company)\n",
    "\n",
    "# description\n",
    "description_element = soup.find('div', class_='jobsearch-jobDescriptionText')\n",
    "if description_element:\n",
    "    description = description_element.text\n",
    "    # print(description)\n",
    "\n",
    "# requirements\n",
    "\n",
    "# benefits\n",
    "benefits_element = soup.find('div', id='benefits').find_all('ul')\n",
    "if benefits_element:\n",
    "    benefits = \"\"\n",
    "    for ul in benefits_element:\n",
    "        list_items = ul.find_all('li')\n",
    "        for li in list_items:\n",
    "            benefits += li.get_text()+\", \"\n",
    "    # print(benefits)\n",
    "\n",
    "# telecommuting\n",
    "# has_company_logo\n",
    "# has_questions\n",
    "\n",
    "# employment_type\n",
    "Full_occurrences = soup.find_all(string=\"Full-time\")\n",
    "Part_occurrences = soup.find_all(string=\"Part-time\")\n",
    "Temp_occurrences = soup.find_all(string=\"Temporary\")\n",
    "Contract_occurrences = soup.find_all(string=\"Contract\")\n",
    "if Full_occurrences:\n",
    "    employment_type = \"Full-Time\"\n",
    "elif Part_occurrences:\n",
    "    employment_type = \"Part-Time\"\n",
    "elif Temp_occurrences:\n",
    "    employment_type = \"Temporary\"\n",
    "elif Contract_occurrences:\n",
    "    employment_type = \"Contract\"\n",
    "\n",
    "# required_experience\n",
    "# required_education\n",
    "# industry\n",
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-Time\n"
     ]
    }
   ],
   "source": [
    "print(employment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
